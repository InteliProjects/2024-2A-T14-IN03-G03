{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propósito:\n",
    "\n",
    "Esse notebook traz um estudo sobre o desenvolvimento de um algoritimo que visa prever o resultado de embates entre dois times de futebol a partir de sua escalação e jogadores.\n",
    "\n",
    "Durante a leitura você percebera que dezenas de testes e tratamentos de dados foram realizados, visando trazer o máximo de acurácia e precisão possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "  min_data = np.min(data)\n",
    "  max_data = np.max(data)\n",
    "\n",
    "  return (data - min_data) / (max_data - min_data)\n",
    "\n",
    "def dect_Outliers(dados):\n",
    "  q1 = np.percentile(dados,25)\n",
    "  q3 = np.percentile(dados,75)\n",
    "\n",
    "  iiq = q3 - q1   \n",
    "\n",
    "  min = q1 - 2 * iiq\n",
    "  max = q3 + 2 * iiq\n",
    "\n",
    "  outliers = [x for x in dados if x < min or x > max]\n",
    "\n",
    "  return outliers\n",
    "\n",
    "def trat_outlier_per_quartis(coluna, fator):\n",
    "    # Calcula os quartis\n",
    "    Q1 = coluna.quantile(0.25)\n",
    "    Q3 = coluna.quantile(0.75)\n",
    "    IQR = Q3 - Q1  # Intervalo interquartil\n",
    "\n",
    "    # Calcula os limites de outliers\n",
    "    limite_inferior = Q1 - fator * IQR\n",
    "    limite_superior = Q3 + fator * IQR\n",
    "\n",
    "    # Trata os outliers\n",
    "    coluna_tratada = coluna.apply(lambda x: Q1 if x < limite_inferior else (Q3 if x > limite_superior else x))\n",
    "\n",
    "    return coluna_tratada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "partidas_serie_a = pd.read_json('../../assets/brasileirao_serie_a_2024.json')\n",
    "players_result_per_escalation = pd.read_csv('./player_results_per_escalation.csv')\n",
    "\n",
    "matches_ibm = pd.read_csv('../../assets/matches.csv')\n",
    "matches_fifa = pd.json_normalize(partidas_serie_a['Results'])\n",
    "\n",
    "matches_fifa.to_csv('./matches_fifa.csv', index=False)\n",
    "\n",
    "players = pd.read_csv('../../assets/players_atualizada.csv')\n",
    "\n",
    "events = pd.read_json('../../assets/matches_events.json')\n",
    "events = events[[\n",
    "  'IdMatch',\n",
    "  'Event'\n",
    "]]\n",
    "events = events.explode('Event')\n",
    "\n",
    "players = players.apply(lambda col: col.str.replace(',', '.') if col.dtype == 'object' else col)\n",
    "\n",
    "# substitui NaN por 0\n",
    "players = players.fillna(0)\n",
    "\n",
    "# remove a coluna eventos que esteja NaN\n",
    "events = events.dropna(subset=['Event'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento da tabela players\n",
    "\n",
    "Visando remover ruídos no modelo, estamos utilizando um sistema de remoção de outliers e normalização de colunas.\n",
    "\n",
    "> Os outliers são dados que se diferenciam drasticamente de todos os outros. Em outras palavras, um outlier é um valor que foge da normalidade e que pode (e provavelmente irá) causar anomalias nos resultados obtidos por meio de algoritmos e sistemas de análise.\n",
    "\n",
    "ANALYTICS, A. A. Outliers, o que são e como tratá-los em uma análise de dados? Disponível em: <https://aquare.la/o-que-sao-outliers-e-como-trata-los-em-uma-analise-de-dados/>.\n",
    "\n",
    "<br />\n",
    "\n",
    "> A normalização é focada na prevenção de problemas com repetição e atualização de dados, assim como o cuidado com a integridade dos dados. Este conceito foi apresentado originalmente em um artigo científico publicado pela IBM de autoria do matemático Edgar F. Codd, intitulado \"Um modelo de dados relacionais para grandes bancos de dados compartilhados\" (1970). Codd se centra nos valores dos elementos relacionados no banco de dados, não em ligações ou agrupamentos específicos.\n",
    " \n",
    "Normalização em Banco de Dados - Estrutura. Disponível em: <https://www.alura.com.br/artigos/normalizacao-banco-de-dados-estrutura>.\n",
    "\n",
    "<br />\n",
    "\n",
    "Realizamos a seleção das colunas de jogadores visando destinguir diferentes grupos para entender como funciona a dinamica de jogo entre os times.\n",
    "Analisamos os dados e identificamos as seguinte colunas como primordiais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_players = players[[\n",
    "  'goals_overall',\n",
    "  'crosses_per_game_overall',\n",
    "  'dribbles_per_game_overall',\n",
    "  'interceptions_per_game_overall',\n",
    "  'assists_per_game_overall',\n",
    "  'penalty_goals',\n",
    "]].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "total_features = len(players.columns)\n",
    "outliers_list = []\n",
    "\n",
    "for i, col in enumerate(sample_players.columns):\n",
    "  outliers = dect_Outliers(sample_players[col])\n",
    "  if outliers:\n",
    "    outliers_list.append({\n",
    "      'columnName': col,\n",
    "      'outliers': outliers\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterização de dados\n",
    "Usando as colunas encontradas anteriormente, iniciamos um processo que chamamos de clusterização. A cluterização tem como objetivo identificar \"Clusters\" de jogadores e entender como eles se relacionam entre si.\n",
    "\n",
    "Para realizarmos a clusterização, utilizamos KMeans, que é um modelo não supervisionado que encontra correlações entre as colunas e os dados, atribuindo uma classe aos mesmos.\n",
    "\n",
    "> É um algoritmo de clusterização (agrupamento) não supervisionado, baseado na definição de centroides que representam clusters. O “K” refere-se ao número de centroides (clusters) definidos previamente e o “Means” à média dos pontos em cada cluster que determina a posição de seu centroide.\n",
    "\n",
    "ESCOLA DNC. K-Means: conheça esse algoritmo poderoso para clusterização - Blog DNC. Disponível em: <https://www.escoladnc.com.br/blog/kmeans-o-algoritmo-poderoso-para-clusterizacao-nao-supervisionada/#:~:text=O%20K%2DMeans%20%C3%A9%20um>. Acesso em: 13 set. 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3)\n",
    "kmeans_features = sample_players.iloc[:, :4]\n",
    "model.fit(kmeans_features)  \n",
    "sample_players['cluster'] = model.predict(kmeans_features)\n",
    "sample_players['cluster'].value_counts()\n",
    "sample_players['cluster'] = sample_players['cluster'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(sample_players, dimensions=sample_players.iloc[:, :7].columns, color='cluster', height=2000)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As relações acima nos ajuda a encontrar as seguintes hipóteses:\n",
    "\n",
    "1 - Há uma relação clara entre jogadores que cruzam e driblam mais (dribbles_per_game_overall x crosses_per_game_overall)\n",
    "<br>\n",
    "2 - Há uma relação clara entre jogadores que cruzam e interceptam (crosses_per_game_overall x interceptions_per_game_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = px.scatter_3d(\n",
    "  x=sample_players['goals_overall'], \n",
    "  y=sample_players['interceptions_per_game_overall'], \n",
    "  z=sample_players['crosses_per_game_overall'], \n",
    "  color=sample_players['cluster'])\n",
    "\n",
    "# change x y z labels\n",
    "graphs.update_layout(scene = dict(\n",
    "  xaxis_title='Gols',\n",
    "  yaxis_title='Interceptações',\n",
    "  zaxis_title='Dribles'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Jogadores que driblam menos e fazem menos interceptações, estão mais propicios a fazer gols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = px.scatter_3d(\n",
    "  x=sample_players['goals_overall'], \n",
    "  y=sample_players['crosses_per_game_overall'], \n",
    "  z=sample_players['dribbles_per_game_overall'], \n",
    "  color=sample_players['cluster'])\n",
    "\n",
    "# change x y z labels\n",
    "graph.update_layout(scene = dict(\n",
    "  xaxis_title='Gols',\n",
    "  yaxis_title='Cruzamentos',\n",
    "  zaxis_title='Dribles'\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = px.scatter_3d(\n",
    "  x=sample_players['goals_overall'], \n",
    "  y=sample_players['crosses_per_game_overall'], \n",
    "  z=sample_players['interceptions_per_game_overall'], \n",
    "  color=sample_players['cluster'])\n",
    "\n",
    "# change x y z labels\n",
    "graph.update_layout(scene = dict(\n",
    "  xaxis_title='Gols',\n",
    "  yaxis_title='Cruzamentos',\n",
    "  zaxis_title='Interceptações'\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = px.scatter_3d(\n",
    "  x=sample_players['goals_overall'], \n",
    "  y=sample_players['crosses_per_game_overall'], \n",
    "  z=sample_players['interceptions_per_game_overall'], \n",
    "  color=sample_players['cluster'])\n",
    "# change x y z labels\n",
    "graph.update_layout(scene = dict(\n",
    "    xaxis_title='Gols',\n",
    "    yaxis_title='Cruzamentos',\n",
    "    zaxis_title='Interceptações'\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de dimencionalidade\n",
    "\n",
    "Após encontrar as correlações entre os jogadores e seus diferentes clusters, buscamos reduzir o número de variáveis também conhecidas como features. Para isso utilizamos o PCA (Principal Component Analysis)\n",
    "\n",
    "> Análise de Componentes Principais (PCA) é uma técnica fundamental em análise de dados e aprendizado de máquina que tem aplicações em uma ampla gama de campos, incluindo ciência de dados, visão computacional, reconhecimento de padrões e muito mais. PCA é utilizada para reduzir a dimensionalidade dos dados, preservando ao máximo a variabilidade presente nos mesmos.\n",
    "\n",
    "HUGO, V. Análise de Componentes Principais (PCA) - Victor Hugo F. Francheto - Medium. Disponível em: <https://medium.com/@victor.h.f.francheto/an%C3%A1lise-de-componentes-principais-pca-a1e7361de059>. Acesso em: 13 set. 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "features = sample_players.drop(columns=['cluster'], axis=1)\n",
    "pca.fit(features.iloc[:, :7])\n",
    "pca_samples = pca.transform(features.iloc[:, :7])\n",
    "pca_samples = pd.DataFrame(\n",
    "  pca_samples, \n",
    "  columns=[\n",
    "    'player_PC1', \n",
    "    'player_PC2'\n",
    "])\n",
    "pca_samples['cluster'] = sample_players['cluster']\n",
    "pca_samples['current_club'] = players['current_club']\n",
    "pca_samples['position'] = players['position']\n",
    "pca_samples['full_name'] = players['full_name']\n",
    "\n",
    "\n",
    "teams_players_cluster = pca_samples.groupby('current_club')['cluster'].value_counts().unstack(fill_value=0) \n",
    "\n",
    "# Contagem de clubes\n",
    "club_counts = pca_samples['current_club'].value_counts()\n",
    "teams_players_cluster = teams_players_cluster.div(club_counts, axis=0)\n",
    "\n",
    "# Renomear as colunas para refletir os clusters\n",
    "teams_players_cluster.columns = [f'cluster_{col}' for col in teams_players_cluster.columns]\n",
    "teams_players_cluster = teams_players_cluster.reset_index()\n",
    "\n",
    "# Plota gráfico Scree\n",
    "fig = px.bar(x=range(1, len(pca.explained_variance_ratio_)+1),\n",
    "             y=pca.explained_variance_ratio_,\n",
    "             title='Gráfico Scree (Relação de Percentual de Variância e Componente Principal)',\n",
    "             labels={'x':'Componente Principal', 'y':'Percentual de variância'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "  pca_samples, \n",
    "  x='player_PC1', \n",
    "  y='player_PC2',\n",
    "  color='cluster'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.read_csv('../../assets/teams_atualizada.csv')\n",
    "teams = teams[[\n",
    "  'shots_on_target', \n",
    "  'shots',\n",
    "  'average_possession', \n",
    "  'average_total_goals_per_match', \n",
    "  'win_percentage', \n",
    "  'fts_percentage', \n",
    "  'common_name',\n",
    "  'points_per_game',\n",
    "  'fouls',\n",
    "  'wins',\n",
    "  'draws',\n",
    "  'losses'\n",
    "]]\n",
    "\n",
    "teams['points_per_game'] = trat_outlier_per_quartis(teams['points_per_game'], 2)\n",
    "teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_pca = PCA(n_components=2)\n",
    "teams_features = teams.drop(columns=['common_name'], axis=1)\n",
    "teams_pca.fit(teams_features)\n",
    "pca_teams_samples = teams_pca.transform(teams_features)\n",
    "pca_teams_samples = pd.DataFrame(pca_teams_samples, columns=['team_PC1', 'team_PC2'])\n",
    "pca_teams_samples['common_name'] = teams['common_name']\n",
    "\n",
    "pca_teams_samples = pca_teams_samples.merge(teams_players_cluster, left_on='common_name', right_on='current_club')\n",
    "\n",
    "# Plota gráfico Scree\n",
    "fig = px.bar(x=range(1, len(teams_pca.explained_variance_ratio_)+1),\n",
    "             y=teams_pca.explained_variance_ratio_,\n",
    "             title='Gráfico Scree (Relação de Percentual de Variância e Componente Principal)',\n",
    "             labels={'x':'Componente Principal', 'y':'Percentual de variância'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3)\n",
    "kmeans_teams_features = pca_teams_samples[['team_PC1', 'team_PC2']]\n",
    "model.fit(kmeans_teams_features)  \n",
    "pca_teams_samples['team_cluster'] = model.predict(kmeans_teams_features)\n",
    "pca_teams_samples['team_cluster'].value_counts()\n",
    "pca_teams_samples['team_cluster'] = pca_teams_samples['team_cluster'].astype(str)\n",
    "\n",
    "px.scatter(\n",
    "  pca_teams_samples, \n",
    "  x='team_PC1', \n",
    "  y='team_PC2',\n",
    "  color='team_cluster'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv('../../assets/matches_atualizada.csv')\n",
    "matches = matches.query('status == \"complete\"')[[\n",
    "  'home_team_name',\n",
    "  'away_team_name',\n",
    "  'home_team_goal_count',\n",
    "  'away_team_goal_count',\n",
    "  'home_pre_match_xg',\t\n",
    "  'away_pre_match_xg',\n",
    "  'home_ppg',\n",
    "  'away_ppg',\n",
    "  'average_goals_per_match_pre_match',\n",
    "  'average_corners_per_match_pre_match',\n",
    "  'btts_percentage_pre_match'\n",
    "]]\n",
    "\n",
    "matches = matches.merge(pca_teams_samples.drop(columns=['current_club']), left_on='home_team_name', right_on='common_name')\n",
    "matches = matches.merge(pca_teams_samples.drop(columns=['current_club']), left_on='away_team_name', right_on='common_name', suffixes=('_home', '_away'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_sample = matches.drop(columns=['common_name_home', 'common_name_away'])\n",
    "\n",
    "# adiciona o vencedor da partida 1 = casa, 2 = fora, 0 = empate\n",
    "matches_sample['winner'] = matches_sample.apply(lambda row: 1 if row['home_team_goal_count'] > row['away_team_goal_count'] else 2 if row['home_team_goal_count'] < row['away_team_goal_count'] else 0, axis=1)\n",
    "\n",
    "# separa a mesma quantidade de casa, fora e empate de forma aleatória\n",
    "home_wins = matches_sample.query('winner == 1')\n",
    "draws = matches_sample.query('winner == 0')\n",
    "away_wins = matches_sample.query('winner == 2')\n",
    "\n",
    "cleaned_matches_sample = pd.concat([\n",
    "  draws.sample(n=55, random_state=42), \n",
    "  away_wins.sample(n=55, random_state=42), \n",
    "  home_wins.sample(n=55, random_state=42)\n",
    "])\n",
    "\n",
    "matches_sample = pd.DataFrame(cleaned_matches_sample).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_pca = PCA(n_components=4)\n",
    "\n",
    "matches_features = matches_sample.drop(columns=[\n",
    "  'home_team_name', \n",
    "  'away_team_name', \n",
    "  'home_team_goal_count', \n",
    "  'away_team_goal_count', \n",
    "  'winner'], axis=1)\n",
    "\n",
    "matches_pca.fit(matches_features)\n",
    "pca_matches_samples = matches_pca.transform(matches_features)\n",
    "pca_matches_samples = pd.DataFrame(\n",
    "  pca_matches_samples, \n",
    "  columns=[\n",
    "    'matches_PC1', \n",
    "    'matches_PC2', \n",
    "    'matches_PC3', \n",
    "    'matches_PC4'])\n",
    "\n",
    "pca_matches_samples['winner'] = matches_sample['winner']\n",
    "pca_matches_samples['home_team_name'] = matches_sample['home_team_name']\n",
    "pca_matches_samples['away_team_name'] = matches_sample['away_team_name']\n",
    "\n",
    "# Plota gráfico Scree\n",
    "fig = px.bar(x=range(1, len(matches_pca.explained_variance_ratio_)+1),\n",
    "  y=matches_pca.explained_variance_ratio_,\n",
    "  title='Gráfico Scree (Relação de Percentual de Variância e Componente Principal)',\n",
    "  labels={'x':'Componente Principal', 'y':'Percentual de variância'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do modelo\n",
    "\n",
    "Após encontrar todos os clusters, reduzir dimencionalidade, realizar limpezas e normalizações e juntar tabelas, iniciamos o treinamento do modelo.\n",
    "\n",
    "Para responder nossa pergunta em questão (Qual time ira ganhar?) vamos utilizar o Random Forest. Um modelo que gera varias arvores binárias e compara os resultados encontrados por elas.\n",
    "\n",
    "> Random forest é um algoritmo de aprendizado de máquina amplamente utilizado, registrado por Leo Breiman e Adele Cutler, que combina o resultado de múltiplas árvores de decisão para chegar a um único resultado. Sua facilidade de uso e flexibilidade impulsionaram sua adoção, pois ele lida com problemas tanto de classificação quanto de regressão.\n",
    "\n",
    "IBM. What is Random Forest? | IBM. Disponível em: <https://www.ibm.com/topics/random-forest#:~:text=Random%20forest%20is%20a%20commonly>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# separa 5 partidas para teste e remove do dataset de treino\n",
    "manual_test = matches_sample.sample(n=5, random_state=42)\n",
    "pca_matches_samples = pca_matches_samples.drop(manual_test.index)\n",
    "\n",
    "X = pca_matches_samples.drop(columns=['winner', 'home_team_name', 'away_team_name'])\n",
    "y = pca_matches_samples['winner']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_test.count()\n",
    "\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_forest.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "matrix_conf = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Acurácia: {(accuracy * 100):10.2f}%')\n",
    "print(f'Matriz de confusão: \\n{matrix_conf}')\n",
    "plt.figure(figsize=(10, 7))\n",
    "heat_map = sns.heatmap(matrix_conf, annot=True)\n",
    "\n",
    "heat_map.set_xlabel('Previsto', fontsize=12)\n",
    "heat_map.set_ylabel('Real', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.merge(matches_sample.drop(columns=[\n",
    "  'home_team_goal_count',\n",
    "  'away_team_goal_count', \n",
    "  'cluster_0_home',\n",
    "  'cluster_1_home', \n",
    "  'cluster_2_home', \n",
    "  'cluster_0_away',\n",
    "  'cluster_1_away', \n",
    "  'cluster_2_away', \n",
    "]), left_index=True, right_index=True)\n",
    "\n",
    "X_test['winner'] = y_test\n",
    "X_test['predicted_winner'] = y_pred \n",
    "\n",
    "X_test.to_csv('./matches_test.csv', index=False)\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_matches_samples['winner'] = pca_matches_samples['winner'].astype(str)\n",
    "\n",
    "px.scatter_3d(\n",
    "  pca_matches_samples, \n",
    "  x='matches_PC1', \n",
    "  y='matches_PC2',\n",
    "  z='matches_PC3',\n",
    "  color='winner'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Após realizar todos os treinamentos tratamentos e demais análises dos resultados do modelo, encontramos uma acurácia abaixo do esperado.\n",
    "Como podemos ver na matriz de confusão que geramos acima, o modelo tem uma certa dificuldade ainda em diferencias vitórias da casa e vitórias do vistiante. Apesar de entender muito bem quando há empates. Ele indica muito menos empates do que as demais situações.\n",
    "\n",
    "## Como aprimorar o modelo para encontrar melhores resultados?\n",
    "\n",
    "Uma das soluçõe que podemos testar, está relacionada aos dados inputados no modelo. Apesar de terem uma correlação direta com a vitória, os dados não trazem uma boa diferenciação para o modelo e isso atrapalha o mesmo.\n",
    "\n",
    "Podemos ainda realizar um tratamento no mesmo, gerando uma normalização para colunas que estão afetando negativamente o modelo e causando ruídos. A adição de dados que diferenciem as vitórias da casa e as vitórias do visitante também se mostram importante. Talvez podemos usar mais dados da casa e do visitante ao invés de dados gerais (não considerar \"Gols Gerais\" e sim \"Gols marcados em casa\")."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
