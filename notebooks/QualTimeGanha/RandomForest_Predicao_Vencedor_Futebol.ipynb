{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  **Modelo Preditivo - Vencedor de Partidas(%)**\n",
    "## **Introdução**\n",
    "Este notebook tem como objetivo desenvolver um modelo preditivo para determinar o time vencedor em uma partida de futebol, utilizando dados fornecidos pela IBM. A análise inclui a preparação dos dados, a construção e a avaliação do modelo, e a visualização dos resultados. O modelo é treinado para prever a probabilidade de vitória do time da casa, do time visitante e de empate.\n",
    "## **Dados**\n",
    "Os dados utilizados neste projeto foram fornecidos pela IBM e consistem em informações sobre partidas de futebol e estatísticas dos times. As principais tabelas são:\n",
    "- **matches.csv**: Contém detalhes sobre as partidas.\n",
    "- **teams.csv**: Contém estatísticas e informações sobre os times.\n",
    "## **1. Importação de Bibliotecas e Dados**\n",
    "O código começa importando as bibliotecas necessárias e carregando os dados dos arquivos CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **pandas**: Manipulação e análise de dados.\n",
    "- **numpy**: Cálculos numéricos e operações matemáticas.\n",
    "- **matplotlib e seaborn**: Criação de gráficos para visualização de dados.\n",
    "- **sklearn**: Conjunto de ferramentas de machine learning, como divisão de dados, criação de modelos, e avaliação de desempenho.\n",
    "- **imblearn**: Para técnicas de balanceamento de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, auc, roc_curve, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss, balanced_accuracy_score\n",
    "\n",
    "matches = pd.read_csv('matches.csv', sep=';')\n",
    "teams = pd.read_csv('teams.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Após carregar os dados, filtramos as partidas que já foram completadas, garantindo que estamos utilizando dados de jogos finalizados para o treinamento do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matches.query(\"status == 'complete'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Processamento dos Dados**\n",
    "Os dados são processados para combinar informações das partidas com estatísticas dos times, criando um DataFrame que inclui as características dos times da casa e visitante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "count = 0;\n",
    "for index, curr_match in matches.iterrows():\n",
    "  \n",
    "  home_team_goals = curr_match.home_team_goal_count\n",
    "\n",
    "  confrontation = {\"winner\": 0}\n",
    "  if(curr_match.home_team_goal_count > curr_match.away_team_goal_count):\n",
    "    confrontation = {\"winner\": 1}\n",
    "  elif(curr_match.home_team_goal_count < curr_match.away_team_goal_count):\n",
    "    confrontation = {\"winner\": 2}\n",
    "\n",
    "  away_data = teams.query('common_name == \"{}\"'.format(curr_match.away_team_name)).drop(\n",
    "    columns=['team_name', 'season',\t'country'])\n",
    "  \n",
    "  home_data = teams.query('common_name == \"{}\"'.format(curr_match.home_team_name)).drop(\n",
    "    columns=['team_name', 'season',\t'country'])\n",
    "\n",
    "  away_data = away_data.rename(columns=lambda col: f'{col}_a')\n",
    "  home_data = home_data.rename(columns=lambda col: f'{col}_h')\n",
    "\n",
    "  confrontation.update(home_data.iloc[0].to_dict())\n",
    "  confrontation.update(away_data.iloc[0].to_dict())\n",
    "  \n",
    "  data.append(confrontation)\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv('./teams_confrontations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A combinação de dados é feita através de consultas às estatísticas dos times no arquivo `teams.csv`, combinando as colunas para que tenhamos os dados do time da casa e do time visitante no mesmo registro. Renomeamos as colunas para distinguir as estatísticas de cada time, utilizando os sufixos `_h` para o time da casa (home) e `_a` para o time visitante (away).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Filtragem e Seleção de Colunas**\n",
    " \n",
    "Para garantir que o modelo seja treinado com dados consistentes, filtramos o DataFrame para incluir apenas jogos onde ambos os times jogaram o mesmo número de partidas, tanto em casa quanto fora. Isso é feito para eliminar potenciais vieses que poderiam surgir de uma discrepância no número de partidas jogadas por cada time.\n",
    " \n",
    "Após essa filtragem, selecionamos as colunas mais relevantes para o treinamento do modelo. Essas colunas incluem:\n",
    "- Número de jogos, vitórias, derrotas e empates.\n",
    "- Gols marcados e sofridos.\n",
    "- Posição na liga.\n",
    "- Cartões, faltas e posse de bola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_games_played_h = data['matches_played_h'].max()\n",
    "max_games_played_a = data['matches_played_a'].max()\n",
    "\n",
    "max_games_played = min(max_games_played_h, max_games_played_a)\n",
    "\n",
    "filtered_data = data[(data['matches_played_h'] == max_games_played) & (data['matches_played_a'] == max_games_played)]\n",
    "\n",
    "matches_played_h_unique = filtered_data['matches_played_h'].nunique()\n",
    "matches_played_a_unique = filtered_data['matches_played_a'].nunique()\n",
    "\n",
    "print(f\"Número único de partidas jogadas em casa: {matches_played_h_unique}\")\n",
    "print(f\"Número único de partidas jogadas fora: {matches_played_a_unique}\")\n",
    "\n",
    "if matches_played_h_unique == 1 and matches_played_a_unique == 1:\n",
    "    print(\"Todos os times jogaram o mesmo número de partidas, tanto em casa quanto fora.\")\n",
    "else:\n",
    "    print(\"Existem diferentes números de partidas jogadas entre os times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_tables = [\n",
    "    'matches_played_a', 'matches_played_h',\n",
    "    'wins_h', 'wins_a',\n",
    "    'draws_h', 'draws_a',\n",
    "    'losses_h', 'losses_a',\n",
    "    'points_per_game_h', 'points_per_game_a',\n",
    "    'league_position_h', 'league_position_a',\n",
    "    'goals_scored_h', 'goals_scored_a',\n",
    "    'goals_conceded_h', 'goals_conceded_a',\n",
    "    'minutes_per_goal_scored_h', 'minutes_per_goal_scored_a',\n",
    "    'btts_count_h', 'btts_count_a',\n",
    "    'shots_h', 'shots_a',\n",
    "    'shots_on_target_h', 'shots_on_target_a',\n",
    "    'shots_off_target_h', 'shots_off_target_a',\n",
    "    'first_team_to_score_percentage_h', 'first_team_to_score_percentage_a',\n",
    "    'fouls_h', 'fouls_a',\n",
    "    'cards_per_match_h', 'cards_per_match_a',\n",
    "    'clean_sheets_h', 'clean_sheets_a',\n",
    "    'goals_scored_home_h', 'goals_scored_away_h',\n",
    "    'goals_conceded_home_h', 'goals_conceded_away_h',\n",
    "    'goals_conceded_home_a', 'goals_conceded_away_a',\n",
    "    'goal_difference_h', 'goal_difference_a',\n",
    "    'home_advantage_percentage_h',\n",
    "    'goals_scored_home_a', 'goals_scored_away_a',\n",
    "    'average_possession_home_a', 'average_possession_away_a',\n",
    "    'average_possession_home_h', 'average_possession_away_h',\n",
    "    'win_percentage_h', 'win_percentage_a',\n",
    "    'btts_percentage_h', 'btts_percentage_a',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Detecção e Tratamento de Outliers**\n",
    "Embora o código para detecção e tratamento de outliers esteja comentado, ele é útil para o processo de análise, especialmente para garantir a qualidade dos dados. O código a seguir foi utilizado para identificar e tratar outliers nos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for col in data.columns:\n",
    "    # Verifica se a coluna é numérica\n",
    "    if np.issubdtype(data[col].dtype, np.number):\n",
    "        mean = data[col].mean()\n",
    "        std_dev = data[col].std()\n",
    "\n",
    "        data['z_score'] = (data[col] - mean) / std_dev\n",
    "        threshold = 2.5\n",
    "        data['is_outlier'] = np.abs(data['z_score']) > threshold\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Plotar todos os pontos\n",
    "        plt.scatter(data.index, data[col], color='blue', label='Valores')\n",
    "\n",
    "        # Plotar os outliers\n",
    "        plt.scatter(data[data['is_outlier'].astype(bool)].index,\n",
    "                    data[data['is_outlier'].astype(bool)][col],\n",
    "                    color='red', label='Outliers', marker='o', edgecolor='black')\n",
    "\n",
    "        # Adicionar títulos e legendas\n",
    "        plt.title(col)\n",
    "        plt.xlabel('Índice')\n",
    "        plt.ylabel('Valores')\n",
    "        plt.axhline(y=mean, color='gray', linestyle='--', label='Média')\n",
    "        plt.axhline(y=mean + threshold * std_dev, color='orange', linestyle='--', label='Limite Superior (Média + 3*Desvio Padrão)')\n",
    "        plt.axhline(y=mean - threshold * std_dev, color='orange', linestyle='--', label='Limite Inferior (Média - 3*Desvio Padrão)')\n",
    "        # plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Mostrar o gráfico\n",
    "        plt.show()\n",
    "        sleep(2)\n",
    "        clear_output(wait=True)  # Clears the output after each iteration\n",
    "\n",
    "        # Substitui pela média:\n",
    "        data.loc[data['is_outlier'], col] = mean\n",
    "\n",
    "        if std_dev == 0:\n",
    "            data = data.drop(columns=[col])\n",
    "\n",
    "\n",
    "data = data.drop(columns=['z_score', 'is_outlier'])\n",
    "\n",
    "data.to_csv('times.csv')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Identificação de Outliers**: O código verifica se cada coluna é numérica e calcula a média e o desvio padrão dos dados. A partir desses valores, calcula o escore Z e identifica os outliers com base em um limiar definido.\n",
    "\n",
    "2. **Visualização dos Outliers**: Utiliza gráficos de dispersão para mostrar os valores e os outliers identificados. As linhas de média e limites superior e inferior são plotadas para melhor visualização.\n",
    "\n",
    "3. **Tratamento dos Outliers**: Os valores identificados como outliers são substituídos pela média da coluna correspondente. Se o desvio padrão for zero, a coluna é removida, pois não contribui para a análise.\n",
    "\n",
    "4. **Salvar os Dados**: Após o tratamento dos outliers, os dados limpos são salvos em um arquivo CSV chamado `times.csv`.\n",
    "\n",
    "\n",
    "A execução repetida desse código possa ser demorada e gerar muitas tabelas, ele é fundamental para garantir que os dados utilizados para treinar o modelo estejam livres de valores extremos que possam distorcer os resultados. O tratamento de outliers melhora a qualidade dos dados e a precisão do modelo preditivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Treinamento e Avaliação do Modelo**\n",
    "\n",
    "Foi realizada a divisão dos dados em conjuntos de treino e teste. Utilizamos o **RandomForestClassifier**, um algoritmo capaz de lidar com conjuntos de dados complexos e realizar previsões precisas mesmo em cenários onde há muitos recursos disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = filtered_data[selected_tables]\n",
    "y = filtered_data['winner']\n",
    "\n",
    "# Verificar se 'x' e 'y' não estão vazios antes da divisão\n",
    "print(f\"Tamanho de x: {x.shape}\")\n",
    "print(f\"Tamanho de y: {y.shape}\")\n",
    "\n",
    "# Se 'x' ou 'y' estiver vazio, exibir uma mensagem e parar o processamento\n",
    "if x.shape[0] == 0 or y.shape[0] == 0:\n",
    "    print(\"O conjunto de dados está vazio após o pré-processamento. Verifique as etapas de filtragem.\")\n",
    "else:\n",
    "    # Dividir em treino e teste\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "    print(\"Conjunto de dados dividido com sucesso em treino e teste.\")\n",
    "\n",
    "# Dividir em treino e teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamos o modelo e avaliamos a sua acurácia, que é uma métrica importante para medir o desempenho inicial do modelo. Em seguida, geramos um relatório de classificação para obter mais detalhes sobre o desempenho nas diferentes classes de resultado (vitória do time da casa, visitante e empate).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "randomForest.fit(x_train, y_train)\n",
    "\n",
    "y_pred = randomForest.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=[1, 2, 0])\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Vitória do time da casa', 'Vitória do time de fora', 'Empate'], yticklabels=['Vitória do time da casa', 'Vitória do time de fora', 'Empate'])\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Atual')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir da análise da matriz de confusão e dos gráficos gerados, conseguimos identificar onde o modelo tem um bom desempenho e onde ele ainda pode ser otimizado. Utilizamos técnicas de balanceamento de dados, como o oversampling, para garantir que o modelo seja treinado com um conjunto de dados balanceado e, assim, melhorar sua performance geral.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Análise do Balanceamento dos Dados**  ##\n",
    "Para melhorar a performance do modelo, analisamos o balanceamento do modelo para entender como a distribuição dos dados está afetando no desempenho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 10))\n",
    "\n",
    "data['winner'].value_counts().plot(kind='bar', ax=ax[0])\n",
    "data['winner'].value_counts().plot(kind='pie', ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No gráfico acima, pode-se observar um claro desbalanceamento dos valores da coluna ``winner``, com uma predominância de **vitórias da casa**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Balanceamento dos Dados**\n",
    "Para melhorar a performance do modelo, aplicamos técnicas de balanceamento para lidar com a desproporção das classes e resultar em uma base de dados balanceada. \n",
    "Essa abordagem evita viés no modelo, além de fazer com que ele seja mais preciso e generalize melhor. Isso é especialmente importante no contexto do projeto, onde a variedade de resultados (vitórias da casa, empates e vitórias do visitante) precisa ser capturada corretamente para que o modelo possa fazer previsões mais confiáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empate = data.query('winner == 0')\n",
    "data_cleaned = data.query('winner != 0')\n",
    "\n",
    "data_cleaned = pd.concat([data_cleaned, empate.sample(n=57, random_state=42)])\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 10))\n",
    "\n",
    "data_cleaned['winner'].value_counts().plot(kind='bar', ax=ax[0])\n",
    "data_cleaned['winner'].value_counts().plot(kind='pie', ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_resampled, y_resampled = oversample.fit_resample(data_cleaned.drop('winner', axis=1), data_cleaned['winner'])\n",
    "data_cleaned = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 10))\n",
    "\n",
    "data_cleaned['winner'].value_counts().plot(kind='bar', ax=ax[0])\n",
    "data_cleaned['winner'].value_counts().plot(kind='pie', ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_resampled, y_resampled = oversample.fit_resample(data_cleaned.drop('winner', axis=1), data_cleaned['winner'])\n",
    "\n",
    "data_cleaned_balanced = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 10))\n",
    "data_cleaned_balanced['winner'].value_counts().plot(kind='bar', ax=ax[0])\n",
    "data_cleaned_balanced['winner'].value_counts().plot(kind='pie', ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Avaliação do Modelo com Dados Balanceados**\n",
    "Treinamos e avaliamos o modelo com os dados balanceados para verificar melhorias na performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_balanced = data_cleaned_balanced[selected_tables]\n",
    "y_balanced = data_cleaned_balanced['winner']\n",
    "\n",
    "X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced = train_test_split(X_balanced, y_balanced, test_size=0.25, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_balanced = scaler.fit_transform(X_train_balanced)\n",
    "X_test_balanced = scaler.transform(X_test_balanced)\n",
    "\n",
    "rf_model_balanced = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_model_balanced.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_pred_balanced = rf_model_balanced.predict(X_test_balanced)\n",
    "\n",
    "\n",
    "print(f\"Acurácia: {accuracy_score(y_test_balanced, y_pred_balanced) * 100:.2f}%\")\n",
    "print(classification_report(y_test_balanced, y_pred_balanced))\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_balanced, y_pred_balanced, labels=[1, 2, 0])\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Vitória do time da casa', 'Vitória do time de fora', 'Empate'], yticklabels=['Vitória do time da casa', 'Vitória do time de fora', 'Empate'])\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Previsão de Resultados**\n",
    "Utilizamos o modelo treinado para prever o resultado de uma partida específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_match(home_team, away_team, rf_model_balanced, teams, scaler):\n",
    "    \n",
    "    home_data = teams.query('common_name == \"{}\"'.format(home_team)).drop(columns=['common_name']).iloc[0].to_dict()\n",
    "    away_data = teams.query('common_name == \"{}\"'.format(away_team)).drop(columns=['common_name']).iloc[0].to_dict()\n",
    "    \n",
    "    home_data = {f'{k}_h': v for k, v in home_data.items()}\n",
    "    away_data = {f'{k}_a': v for k, v in away_data.items()}\n",
    "    \n",
    "    match_data = {**home_data, **away_data}\n",
    "    \n",
    "    match_df = pd.DataFrame([match_data])\n",
    "\n",
    "    missing_cols = [col for col in X_balanced.columns if col not in match_df.columns]\n",
    "    for col in missing_cols:\n",
    "        match_df[col] = 0  \n",
    "  \n",
    "    match_df = match_df[X_balanced.columns]\n",
    "\n",
    "    match_df = scaler.transform(match_df)\n",
    "\n",
    "    prediction = rf_model_balanced.predict_proba(match_df)\n",
    "    \n",
    "    return {\n",
    "        \"home_win_prob\": prediction[0][1],\n",
    "        \"draw_prob\": prediction[0][0],\n",
    "        \"away_win_prob\": prediction[0][2]\n",
    "    }\n",
    "\n",
    "home_team = \"Corinthians\"\n",
    "away_team = \"Atlético GO\"\n",
    "\n",
    "prediction = predict_match(home_team, away_team, rf_model_balanced, teams, scaler)\n",
    "print(f\"Probabilidade de vitória do time da casa ({home_team}): {prediction['home_win_prob'] * 100:.2f}%\")\n",
    "print(f\"Probabilidade de empate: {prediction['draw_prob'] * 100:.2f}%\")\n",
    "print(f\"Probabilidade de vitória do time visitante ({away_team}): {prediction['away_win_prob'] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. Curva ROC**\n",
    "Plotamos a curva ROC para avaliar a capacidade do modelo de classificar corretamente as partidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred_proba = rf_model_balanced.predict_proba(X_test_balanced)[:, 1] \n",
    "y_true = y_test_balanced\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred_balanced, pos_label=2)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--') \n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **11. Balanceamento dos Dados com RandomOverSampler**\n",
    "- O balanceamento dos dados é feito utilizando a técnica de **Random Over-Sampling** com a classe `RandomOverSampler` da biblioteca `imbalanced-learn`. Essa técnica aumenta a quantidade de exemplos da classe minoritária duplicando-os até igualar a quantidade de exemplos das classes majoritárias, o que ajuda a evitar que o modelo favoreça a classe com mais exemplos durante o treinamento.\n",
    "- Após aplicar o `RandomOverSampler`, os dados são divididos em conjuntos de treino e teste utilizando a função `train_test_split`, garantindo que 70% dos dados sejam usados para treinar o modelo e 30% para teste.\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "x_resampled, y_resampled = ros.fit_resample(X_balanced, y_balanced)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **12. Escalonamento das Features**\n",
    "- As features são normalizadas usando o **StandardScaler**, o que transforma os dados para que eles tenham média zero e desvio padrão igual a 1. Isso é importante para melhorar o desempenho de muitos algoritmos de machine learning, especialmente aqueles que utilizam distâncias, como RandomForest.\n",
    "- O escalonamento é aplicado tanto aos dados de treino quanto aos de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **13. Definição do Grid de Hiperparâmetros**\n",
    "- Um dicionário `param_grid` é criado para definir diferentes combinações de hiperparâmetros do modelo **Random Forest** que serão testadas. Os hiperparâmetros incluem:\n",
    "    - `n_estimators`: Número de árvores na floresta.\n",
    "    - `max_depth`: Profundidade máxima das árvores.\n",
    "    - `min_samples_split`: Número mínimo de amostras para dividir um nó.\n",
    "    - `min_samples_leaf`: Número mínimo de amostras em uma folha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **14. Treinamento do Modelo com GridSearchCV**\n",
    "- O **RandomForestClassifier** é instanciado com a opção `class_weight='balanced'`, para lidar melhor com classes desbalanceadas sem a necessidade de balanceamento adicional.\n",
    "- Utiliza-se o **GridSearchCV** para buscar as melhores combinações de hiperparâmetros definidos no `param_grid`, com a métrica de avaliação sendo o **F1 macro** e utilizando validação cruzada com 5 folds (cv=5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "grid_search = GridSearchCV(randomForest, param_grid, cv=5, scoring='f1_macro')\n",
    "grid_search.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **15. Avaliação do Melhor Modelo com Dados Balanceados**\n",
    "- O melhor modelo encontrado pelo `GridSearchCV` é recuperado com `grid_search.best_estimator_`.\n",
    "- O modelo é avaliado no conjunto de teste. As métricas de avaliação incluem:\n",
    "    - **Acurácia**: Percentual de previsões corretas.\n",
    "    - **F1 Score macro**: Média do F1 score para cada classe, considerando a distribuição de classes desbalanceada.\n",
    "    - **ROC AUC**: Área sob a curva ROC para a previsão de probabilidades das classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_balanced = grid_search.best_estimator_\n",
    "\n",
    "y_pred_balanced = best_model_balanced.predict(x_test_scaled)\n",
    "accuracy_balanced = accuracy_score(y_test, y_pred_balanced)\n",
    "f1_balanced = f1_score(y_test, y_pred_balanced, average='macro')\n",
    "roc_auc_balanced = roc_auc_score(y_test, best_model_balanced.predict_proba(x_test_scaled), multi_class='ovr')\n",
    "\n",
    "print(f\"Acurácia: {accuracy_balanced * 100:.2f}%\")\n",
    "print(f\"F1 Score (macro): {f1_balanced:.2f}\")\n",
    "print(f\"AUC-ROC: {roc_auc_balanced:.2f}\")\n",
    "print(classification_report(y_test, y_pred_balanced))\n",
    "\n",
    "conf_matrix_balanced = confusion_matrix(y_test, y_pred_balanced, labels=[1, 2, 0])\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_balanced, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Vitória Casa', 'Vitória Fora', 'Empate'], \n",
    "            yticklabels=['Vitória Casa', 'Vitória Fora', 'Empate'])\n",
    "plt.xlabel('Previsão')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão com Dados Balanceados')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise das Métricas de Avaliação**\n",
    "1. **Acurácia**: \n",
    "   - A **acurácia** foi de **72.22%**, o que significa que o modelo acertou aproximadamente 72% das previsões. Isso indica um desempenho geral satisfatório, mas existem algumas áreas que precisam de melhorias, como a classificação de vitórias da casa e vitórias do time de fora.\n",
    "\n",
    "2. **Precision**: A precisão para cada classe reflete a proporção de resultados positivos reais entre aqueles previstos como positivos. A classe **Vitória Fora** (classe 2) tem uma precisão de 0.77, que é um bom valor, enquanto a classe **Empate** (classe 0) tem uma precisão de 0.71.\n",
    "  \n",
    "3. **Recall**: O recall mede a proporção de verdadeiros positivos corretamente identificados pelo modelo. A classe **Vitória da Casa** (classe 1) tem o recall mais baixo (0.52), sugerindo que o modelo tem dificuldade em identificar corretamente as vitórias da casa.\n",
    "\n",
    "4. **F1 Score (macro)**:\n",
    "   - O **F1 Score macro** é **0.71**, uma média harmônica da precisão e do recall, considerando o equilíbrio entre os diferentes tipos de erro. Este valor sugere que o modelo está balanceado nas previsões entre as classes.\n",
    "   - A classe **Vitória da Casa** tem um F1 Score menor (0.62), refletindo a dificuldade do modelo em prever corretamente essas vitórias. O F1 Score de **Empate**(0.80) e **Vitória Fora**(0.71) indicam uma performance mais estável para essas classes.\n",
    "\n",
    "5. **AUC-ROC**:\n",
    "   - O valor **AUC-ROC** de **0.89** indica uma excelente habilidade de classificação entre as três classes. Este valor próximo de 1 mostra que o modelo é capaz de distinguir bem entre empates, vitórias da casa e vitórias fora.\n",
    "\n",
    "6. **Matriz de confusão**:\n",
    "   - **Vitória da Casa (Classe 1)**: O modelo previu corretamente 17 das 33 vitórias da casa. No entanto, houve 9 erros ao prever vitórias da casa como vitórias do time fora, e 7 erros ao prever vitórias como empates.\n",
    "   - **Vitória do Time de Fora (Classe 2)**: O modelo acertou 27 das 38 vitórias do time de fora. Os erros restantes incluíram 4 casos de previsão como vitória da casa e 7 como empates.\n",
    "   - **Empates (Classe 0)**: Dos 37 empates, o modelo previu corretamente 34, errando 1 vez ao prever como vitória da casa e 2 vezes ao prever como vitória do time de fora.\n",
    "\n",
    "**Considerações Finais**\n",
    "\n",
    "O modelo de Random Forest balanceado apresentou uma performance razoável, com uma **acurácia de 72.22%** e um **AUC-ROC de 0.89**. No entanto, a classe **Vitória da Casa** foi a que apresentou o maior número de erros, refletido também no F1 Score mais baixo. Esse comportamento pode estar relacionado à variabilidade nos fatores que levam um time a vencer em casa, e à dificuldade do modelo em captar essas variações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **16. Função para Prever um Jogo Específico**\n",
    "\n",
    "Utilizamos a mesma função utilizada anteriormente para realizar as previsões.\n",
    "\n",
    "- A função `predict_match` permite prever o resultado de um jogo entre dois times específicos (informados por `home_team` e `away_team`).\n",
    "- A função busca as informações dos times na tabela `teams`, ajusta o formato dos dados para que eles sejam compatíveis com o modelo e, em seguida, aplica o modelo para prever as probabilidades de vitória para o time da casa, empate ou vitória do time visitante.\n",
    "- As probabilidades são retornadas como um dicionário.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_match(home_team, away_team, model, teams, scaler):\n",
    "    \n",
    "    home_data = teams.query('common_name == \"{}\"'.format(home_team)).drop(columns=['common_name']).iloc[0].to_dict()\n",
    "    away_data = teams.query('common_name == \"{}\"'.format(away_team)).drop(columns=['common_name']).iloc[0].to_dict()\n",
    "    \n",
    "    home_data = {f'{k}_h': v for k, v in home_data.items()}\n",
    "    away_data = {f'{k}_a': v for k, v in away_data.items()}\n",
    "    \n",
    "    match_data = {**home_data, **away_data}\n",
    "    \n",
    "    match_df = pd.DataFrame([match_data])\n",
    "\n",
    "    missing_cols = [col for col in x_train.columns if col not in match_df.columns]\n",
    "    for col in missing_cols:\n",
    "        match_df[col] = 0  \n",
    "  \n",
    "    match_df = match_df[x_train.columns]\n",
    "\n",
    "    match_df = scaler.transform(match_df)\n",
    "\n",
    "    prediction = model.predict_proba(match_df)\n",
    "    \n",
    "    return {\n",
    "        \"home_win_prob\": prediction[0][1],\n",
    "        \"draw_prob\": prediction[0][0],\n",
    "        \"away_win_prob\": prediction[0][2]\n",
    "    }\n",
    "\n",
    "home_team = \"Corinthians\"\n",
    "away_team = \"Atlético GO\"\n",
    "\n",
    "prediction = predict_match(home_team, away_team, best_model_balanced, teams, scaler)\n",
    "print(f\"Probabilidade de vitória do time da casa ({home_team}): {prediction['home_win_prob'] * 100:.2f}%\")\n",
    "print(f\"Probabilidade de empate: {prediction['draw_prob'] * 100:.2f}%\")\n",
    "print(f\"Probabilidade de vitória do time visitante ({away_team}): {prediction['away_win_prob'] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **17. Importância das Features**\n",
    "- As features que mais influenciam no modelo são apresentadas no gráfico abaixo. A importância de cada feature foi medida com base na capacidade de melhoria no poder de decisão em cada árvore da floresta.\n",
    "- Algumas features são mais importantes porque possuem uma alta correlação com o resultado, como por exemplo a performance recente dos times e o histórico de vitórias em casa.\n",
    "- **Justificativa**: Na próxima sprint, será feita uma reavaliação dessas features com base nos resultados obtidos. Novas features poderão ser adicionadas ou removidas conforme necessário.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "importances = best_model_balanced.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]  # Ordenar as features por importância\n",
    "\n",
    "# Exibir as features com maior importância\n",
    "print(\"Importância das Features:\")\n",
    "for f in range(x_train.shape[1]):\n",
    "    print(f\"{f + 1}. {x_train.columns[indices[f]]} ({importances[indices[f]]:.4f})\")\n",
    "\n",
    "# Plotar a importância das features\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Importância das Features\")\n",
    "plt.bar(range(x_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(x_train.shape[1]), [x_train.columns[i] for i in indices], rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importância')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **18. Métricas Adicionais: Log Loss e Balanced Accuracy**\n",
    "- Além das métricas já calculadas (acurácia, F1 Score), outras métricas são fundamentais para uma análise mais precisa do desempenho do modelo.\n",
    "    - **Log Loss**: Mede a incerteza das previsões probabilísticas. Quanto menor, melhor.\n",
    "    - **Balanced Accuracy**: Leva em consideração a acurácia balanceada, o que é importante para lidar com dados desbalanceados.\n",
    "\n",
    "As duas métricas serão calculadas a seguir para avaliar a performance do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_value = log_loss(y_test, best_model_balanced.predict_proba(x_test_scaled))\n",
    "\n",
    "balanced_accuracy_value = balanced_accuracy_score(y_test, y_pred_balanced)\n",
    "\n",
    "print(f\"Log Loss: {log_loss_value:.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise das Métricas**\n",
    "\n",
    "- **Log Loss**: O valor de **0.6818** indica que o modelo tem um bom nível de confiança em suas previsões. No entanto, ele ainda tem espaço para melhorar em prever corretamente as probabilidades, especialmente em partidas onde há maior incerteza sobre o resultado.\n",
    "\n",
    "- **Balanced Accuracy**: A **Balanced Accuracy** de **0.7149** indica que o modelo está equilibrado ao lidar com as classes desbalanceadas (por exemplo, vitórias da casa são mais frequentes). Apesar disso, ainda há margem para otimizar as previsões para as classes menos frequentes (vitória fora e empate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusão Geral**\n",
    "Desenvolvemos um modelo preditivo utilizando o algoritmo Random Forest para prever os resultados de partidas de futebol na Série A do Campeonato Brasileiro.\n",
    "\n",
    "As métricas de avaliação do modelo indicaram um desempenho satisfatório, com uma **acurácia de 72.22%** e um **AUC-ROC de 0.89**, evidenciando a capacidade do modelo em distinguir entre os diferentes resultados das partidas. No entanto, notamos que a classe **Vitória da Casa** apresentou desafios, com um recall relativamente baixo, o que sugere a necessidade de uma análise mais aprofundada das características que podem impactar esses resultados.\n",
    "\n",
    "Com base na análise da importância das features, planejamos realizar ajustes nas variáveis utilizadas no modelo para otimizar sua performance. Para a próxima sprint, focaremos em revisar as características que demonstraram maior influência nos resultados, explorando novos dados e potenciais variáveis que possam enriquecer nosso modelo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
