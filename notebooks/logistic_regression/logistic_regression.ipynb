{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão logística\n",
    "\n",
    "### O que é?\n",
    "Podemos resumir regressão logística em uma equação que busca classificar informações a partir do o resultado de uma série de dados. A classificação é binária, podendo sendo \"não\" (0) ou \"sim\" (1). O resultado é encontrado em porcentagem, no qual o valor varia de 0 a 1. O resultado é encontrado em porcentagem, aonde o valor varia de 0 a 1.\n",
    "\n",
    ">A regressão logística estima a probabilidade de ocorrência de um evento, como voto ou não voto, com base em um determinado conjunto de dados de variáveis independentes.\n",
    ">\n",
    "> \\- O que é regressão logística? | IBM. Disponível em: <<https://www.ibm.com/br-pt/topics/logistic-regression>>.\n",
    "\n",
    "\n",
    "A equação a seguir descreve a regressão logística:\n",
    "\n",
    "<img src=\"../assets/image.png\" />\n",
    "\n",
    "\n",
    "A partir disso podemos encontrar os valores e classificá-los.\n",
    "Para testar os valores encontrados, podemos usar um método chamado de \"teste de Hosmer-Lemeshow\".\n",
    "> Depois que o modelo tiver sido calculado, a melhor prática é avaliar o quanto o modelo prevê a variável dependente, o que é chamado de grau de adequação. O teste de Hosmer-Lemeshow é um método popular para avaliar a adequação do modelo.\n",
    ">\n",
    "> \\- O que é regressão logística? | IBM. Disponível em: <<https://www.ibm.com/br-pt/topics/logistic-regression>>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiramente vamos instalar as dependencias\n",
    "Temos que instalar as seguintes dependências\n",
    "\n",
    "[Pandas - https://pandas.pydata.org/](https://pandas.pydata.org/) \n",
    "\n",
    "[Scikit-learn - https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)\n",
    "\n",
    "[Seaborn - https://seaborn.pydata.org/](https://seaborn.pydata.org/)\n",
    "\n",
    "[Matplotlib - https://matplotlib.org/](https://matplotlib.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U scikit-learn pandas seaborn matplotlib unicode --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "import unicodedata\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para remover acentos\n",
    "def remove_acentos(text):\n",
    "  return ''.join(\n",
    "    char for char in unicodedata.normalize('NFD', text)\n",
    "    if unicodedata.category(char) != 'Mn'\n",
    "  )\n",
    "\n",
    "def normalize_data(data):\n",
    "  min_data = np.min(data)\n",
    "  max_data = np.max(data)\n",
    "\n",
    "  return (data - min_data) / (max_data - min_data)\n",
    "\n",
    "def dect_Outliers(dados):\n",
    "  q1 = np.percentile(dados,25)\n",
    "  q3 = np.percentile(dados,75)\n",
    "\n",
    "  iiq = q3 - q1   \n",
    "\n",
    "  min = q1 - 1.5 * iiq\n",
    "  max = q3 + 1.5 * iiq\n",
    "\n",
    "  outliers = [x for x in dados if x < min or x > max]\n",
    "\n",
    "  return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv('../../assets/matches.csv', sep=';')\n",
    "teams = pd.read_csv('../../assets/teams.csv', sep=',')\n",
    "matches_2 = pd.read_csv('../../assets/BRA.csv', sep=',')\n",
    "\n",
    "matches_2['formated_date'] = pd.to_datetime(matches_2['Date'], format='%d/%m/%Y')\n",
    "\n",
    "matches_2.rename(columns={\n",
    "  'Home': 'home_team_name', \n",
    "  'Away': 'away_team_name',\n",
    "  'HG': 'home_team_goal_count',\n",
    "  'AG': 'away_team_goal_count'}, inplace=True)\n",
    "\n",
    "# Captura apenas os dados do Brasileirão 2024\n",
    "matches_2 = matches_2.query('formated_date >= \"2024-04-01\"')\n",
    "\n",
    "# Aplicar a função a uma coluna específica (ex: 'nome')\n",
    "matches['home_team_name'] = matches['home_team_name'].apply(remove_acentos)\n",
    "matches['away_team_name'] = matches['away_team_name'].apply(remove_acentos)\n",
    "matches_2['home_team_name'] = matches_2['home_team_name'].apply(remove_acentos)\n",
    "matches_2['away_team_name'] = matches_2['away_team_name'].apply(remove_acentos)\n",
    "teams['common_name'] = teams['common_name'].apply(remove_acentos)\n",
    "\n",
    "teams = teams.drop(columns=['team_name', 'country', 'season'])\n",
    "matches = matches.drop(columns=['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organização e pré-processamento de dados\n",
    "\n",
    "Aqui iremos organizar os dados em uma estrutura que nosso modelo reconheça\n",
    "\n",
    "A ideia é:\n",
    "\n",
    "- Encontrar os times que jogam entre si\n",
    "- Capturar os dados do time A\n",
    "- Capturar os dados do time B\n",
    "- Capturar o status da partida\n",
    "- Adicionar tudo em uma linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_results = []\n",
    "\n",
    "new_team_names = [\n",
    "  'Vitória',\n",
    "  'Flamengo RJ',\n",
    "  'Cruzeiro',\n",
    "  'Botafogo RJ',\n",
    "  'Grêmio',\n",
    "  'Fluminense',\n",
    "  'Sao Paulo',\n",
    "  'Palmeiras',\n",
    "  'Atletico-MG',\n",
    "  'Athletico-PR',\n",
    "  'Corinthians',\n",
    "  'Vasco',\n",
    "  'Bahia',\n",
    "  'Atlético GO',\n",
    "  'Internacional',\n",
    "  'Bragantino',\n",
    "  'Criciuma',\n",
    "  'Juventude',\n",
    "  'Cuiaba',\n",
    "  'Fortaleza'\n",
    "]\n",
    "\n",
    "resolved_team_names = teams\n",
    "resolved_team_names['common_name'] = new_team_names\n",
    "resolved_team_names['common_name'] = resolved_team_names['common_name'].apply(remove_acentos)\n",
    "resolved_team_names.head()\n",
    "\n",
    "teams_confrontations = []\n",
    "\n",
    "for index, curr_match in matches_2.iterrows():\n",
    "\n",
    "  result = curr_match.home_team_goal_count - curr_match.away_team_goal_count\n",
    "  confrontation = {\"winner\": 0, \"color\": 'blue'} # 0 é empate\n",
    "  if result > 0:\n",
    "    confrontation['winner'] = 1 # 1 é o time da casa\n",
    "    confrontation['color'] = 'verde' # 1 é o time da casa\n",
    "  elif result < 0:\n",
    "    confrontation['winner'] = 2 # 2 é o time visitante\n",
    "    confrontation['color'] = 'vermelho' # 1 é o time da casa\n",
    "\n",
    "  away_data = resolved_team_names.query('common_name == @curr_match.away_team_name')\n",
    "  home_data = resolved_team_names.query('common_name == @curr_match.home_team_name')\n",
    "\n",
    "  away_data = away_data.rename(columns=lambda col: f'{col}_a')\n",
    "  home_data = home_data.rename(columns=lambda col: f'{col}_h')\n",
    "  \n",
    "  # Concatena os dataframes\n",
    "  confrontation.update(away_data.iloc[0].to_dict())\n",
    "  confrontation.update(home_data.iloc[0].to_dict())\n",
    "  \n",
    "  teams_confrontations.append(confrontation)\n",
    "\n",
    "teams_confrontations = pd.DataFrame(teams_confrontations)\n",
    "teams_confrontations.to_csv('./teams_confrontations.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entendendo os dados\n",
    "O gráfico a baixo visa entender a diferença na quantidade de dados entre empates e vitórias\n",
    "- 0 = Empate\n",
    "- 1 = Vitória casa\n",
    "- 2 = Vitória visitante\n",
    "\n",
    "No caso do gráfico a baixo, podemos identificar que há muito mais resultados que deram vitória da casa.\n",
    "Isso atrapalha o modelo pois ele fica enviesado.\n",
    "\n",
    "Para evitar isso, precisamos realizar a limpeza dos dados, igualando o número de vitórias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 10))\n",
    "\n",
    "teams_confrontations['winner'].value_counts().plot(kind='bar', ax=ax[0])\n",
    "teams_confrontations['winner'].value_counts().plot(kind='pie', ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_wins = teams_confrontations.query('winner == 1')\n",
    "cleaned_teams_confrontations = teams_confrontations.query('winner != 1')\n",
    "\n",
    "cleaned_teams_confrontations = pd.concat([cleaned_teams_confrontations, home_wins.sample(n=57, random_state=42)])\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 10))\n",
    "\n",
    "cleaned_teams_confrontations['winner'].value_counts().plot(kind='bar', ax=ax[0])\n",
    "cleaned_teams_confrontations['winner'].value_counts().plot(kind='pie', ax=ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e testagem\n",
    "Inicia o treinamento do modelo com os dados gerados\n",
    "\n",
    "Além disso gerei uma tabela que demonstra os pesos de todas as colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pega as colunas com coeficientes para 0, 1 e 2 que são menores que 0\n",
    "X = teams_confrontations.drop(columns=['winner', 'common_name_a', 'common_name_h', 'color'], axis=1)\n",
    "y = teams_confrontations['winner']\n",
    "\n",
    "feature_names = X.columns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = lm.LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Avaliar a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Adiciona os valores de x as precições\n",
    "X_test['winner'] = y_pred\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.to_csv('./predictions.csv', index=False)\n",
    "\n",
    "pd.DataFrame(model.coef_, columns=feature_names).T.to_csv('./coeficientes.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão\n",
    "Aqui conseguimos ver a matriz de confusão, que mostra os valores corretos contra os valores previstos pela IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plotar a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
